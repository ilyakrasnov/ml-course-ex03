{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Imports\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns; sns.set(color_codes=True)\n",
    "import matplotlib.pyplot as plt\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Read data from source\n",
    "file = 'data.xlsx'\n",
    "df = pd.read_excel(file, header=None)\n",
    "nr_rows = df.shape[0]\n",
    "nr_cols = df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Convert Y feature to number\n",
    "def numberize(value): \n",
    "    return 1 if value == 'M' else 0\n",
    "\n",
    "df[0] = df[0].apply(lambda x: numberize(x))\n",
    "\n",
    "    \n",
    "## Normalize data\n",
    "def norm(vector):\n",
    "    min = np.amin(vector)\n",
    "    max = np.amax(vector)\n",
    "    return (vector - min) / (min - max )\n",
    "\n",
    "for i in range(nr_cols):\n",
    "    df[:][i] = norm(df[:][i])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Split X and Y\n",
    "X = df.ix[:,1:]\n",
    "Y = df.ix[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.521037</td>\n",
       "      <td>-0.022658</td>\n",
       "      <td>-0.545989</td>\n",
       "      <td>-0.363733</td>\n",
       "      <td>-0.593753</td>\n",
       "      <td>-0.792037</td>\n",
       "      <td>-0.703140</td>\n",
       "      <td>-0.731113</td>\n",
       "      <td>-0.686364</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.620776</td>\n",
       "      <td>-0.141525</td>\n",
       "      <td>-0.668310</td>\n",
       "      <td>-0.450698</td>\n",
       "      <td>-0.601136</td>\n",
       "      <td>-0.619292</td>\n",
       "      <td>-0.568610</td>\n",
       "      <td>-0.912027</td>\n",
       "      <td>-0.598462</td>\n",
       "      <td>-0.418864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.643144</td>\n",
       "      <td>-0.272574</td>\n",
       "      <td>-0.615783</td>\n",
       "      <td>-0.501591</td>\n",
       "      <td>-0.289880</td>\n",
       "      <td>-0.181768</td>\n",
       "      <td>-0.203608</td>\n",
       "      <td>-0.348757</td>\n",
       "      <td>-0.379798</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.606901</td>\n",
       "      <td>-0.303571</td>\n",
       "      <td>-0.539818</td>\n",
       "      <td>-0.435214</td>\n",
       "      <td>-0.347553</td>\n",
       "      <td>-0.154563</td>\n",
       "      <td>-0.192971</td>\n",
       "      <td>-0.639175</td>\n",
       "      <td>-0.233590</td>\n",
       "      <td>-0.222878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.601496</td>\n",
       "      <td>-0.390260</td>\n",
       "      <td>-0.595743</td>\n",
       "      <td>-0.449417</td>\n",
       "      <td>-0.514309</td>\n",
       "      <td>-0.431017</td>\n",
       "      <td>-0.462512</td>\n",
       "      <td>-0.635686</td>\n",
       "      <td>-0.509596</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.556386</td>\n",
       "      <td>-0.360075</td>\n",
       "      <td>-0.508442</td>\n",
       "      <td>-0.374508</td>\n",
       "      <td>-0.483590</td>\n",
       "      <td>-0.385375</td>\n",
       "      <td>-0.359744</td>\n",
       "      <td>-0.835052</td>\n",
       "      <td>-0.403706</td>\n",
       "      <td>-0.213433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.210090</td>\n",
       "      <td>-0.360839</td>\n",
       "      <td>-0.233501</td>\n",
       "      <td>-0.102906</td>\n",
       "      <td>-0.811321</td>\n",
       "      <td>-0.811361</td>\n",
       "      <td>-0.565604</td>\n",
       "      <td>-0.522863</td>\n",
       "      <td>-0.776263</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.248310</td>\n",
       "      <td>-0.385928</td>\n",
       "      <td>-0.241347</td>\n",
       "      <td>-0.094008</td>\n",
       "      <td>-0.915472</td>\n",
       "      <td>-0.814012</td>\n",
       "      <td>-0.548642</td>\n",
       "      <td>-0.884880</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.773711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.629893</td>\n",
       "      <td>-0.156578</td>\n",
       "      <td>-0.630986</td>\n",
       "      <td>-0.489290</td>\n",
       "      <td>-0.430351</td>\n",
       "      <td>-0.347893</td>\n",
       "      <td>-0.463918</td>\n",
       "      <td>-0.518390</td>\n",
       "      <td>-0.378283</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.519744</td>\n",
       "      <td>-0.123934</td>\n",
       "      <td>-0.506948</td>\n",
       "      <td>-0.341575</td>\n",
       "      <td>-0.437364</td>\n",
       "      <td>-0.172415</td>\n",
       "      <td>-0.319489</td>\n",
       "      <td>-0.558419</td>\n",
       "      <td>-0.157500</td>\n",
       "      <td>-0.142595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1         2         3         4         5         6         7   \\\n",
       "0   1 -0.521037 -0.022658 -0.545989 -0.363733 -0.593753 -0.792037 -0.703140   \n",
       "1   1 -0.643144 -0.272574 -0.615783 -0.501591 -0.289880 -0.181768 -0.203608   \n",
       "2   1 -0.601496 -0.390260 -0.595743 -0.449417 -0.514309 -0.431017 -0.462512   \n",
       "3   1 -0.210090 -0.360839 -0.233501 -0.102906 -0.811321 -0.811361 -0.565604   \n",
       "4   1 -0.629893 -0.156578 -0.630986 -0.489290 -0.430351 -0.347893 -0.463918   \n",
       "\n",
       "         8         9     ...           21        22        23        24  \\\n",
       "0 -0.731113 -0.686364    ...    -0.620776 -0.141525 -0.668310 -0.450698   \n",
       "1 -0.348757 -0.379798    ...    -0.606901 -0.303571 -0.539818 -0.435214   \n",
       "2 -0.635686 -0.509596    ...    -0.556386 -0.360075 -0.508442 -0.374508   \n",
       "3 -0.522863 -0.776263    ...    -0.248310 -0.385928 -0.241347 -0.094008   \n",
       "4 -0.518390 -0.378283    ...    -0.519744 -0.123934 -0.506948 -0.341575   \n",
       "\n",
       "         25        26        27        28        29        30  \n",
       "0 -0.601136 -0.619292 -0.568610 -0.912027 -0.598462 -0.418864  \n",
       "1 -0.347553 -0.154563 -0.192971 -0.639175 -0.233590 -0.222878  \n",
       "2 -0.483590 -0.385375 -0.359744 -0.835052 -0.403706 -0.213433  \n",
       "3 -0.915472 -0.814012 -0.548642 -0.884880 -1.000000 -0.773711  \n",
       "4 -0.437364 -0.172415 -0.319489 -0.558419 -0.157500 -0.142595  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Add '1' - Feature\n",
    "ones = np.ones(nr_rows, dtype=np.int)\n",
    "X.insert(0, '', ones)\n",
    "X.columns = range(df.shape[1])\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Prepare training set and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X.head(300)\n",
    "Y_train = Y.head(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nr_test_rows = nr_rows - 300\n",
    "X_test = X.tail(nr_test_rows)\n",
    "Y_test = Y.tail(nr_test_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Define helper methods\n",
    "\n",
    "def sig(z):\n",
    "    return 1 / (1 + math.e ** (-1*z))\n",
    "\n",
    "def gradient_descent(X, Y, alpha=0.1, max_iterations=100):\n",
    "    predictions = []\n",
    "    Theta = np.zeros(X.shape[1], dtype=np.int)  # Starting Theta\n",
    "    \n",
    "    while (max_iterations > 0):\n",
    "        prediction = sig(np.dot(X,Theta))\n",
    "        Theta = Theta + (alpha * (Y - prediction) * prediction * (1 - prediction)).dot(X)\n",
    "        predictions.append(prediction)\n",
    "        max_iterations -= 1\n",
    "    \n",
    "    return [predictions, Theta]\n",
    "\n",
    "# Transform p values to 1's and 0's\n",
    "crisp_predictor = lambda x: 1 if x >= 0.5 else 0 \n",
    "\n",
    "def accuracy(crisp, Y): # Subtract predictions from the real values and count the 1's\n",
    "    difference = pd.Series(crisp - Y)\n",
    "    correct_predictions = (difference == 0).sum()\n",
    "    total_predictions = crisp.shape[0]\n",
    "\n",
    "    return (correct_predictions / total_predictions * 100)\n",
    "\n",
    "def quality_test(Theta, X, Y):\n",
    "    predictions = sig(np.dot(X,Theta))\n",
    "    crisp = pd.Series(predictions).apply(crisp_predictor)\n",
    "    quality = accuracy(crisp, Y)\n",
    "    return quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Run predictions by iterations of the algorithm\n",
    "def quality_by_iteration(alpha, max_iterations):\n",
    "    predictions_by_iteration = gradient_descent(X_train, Y_train, alpha, max_iterations)[0]\n",
    "    \n",
    "    \n",
    "    qualities = []\n",
    "    for prediction in predictions_by_iteration:\n",
    "        crisp = pd.Series(prediction).apply(crisp_predictor)\n",
    "        quality = accuracy(crisp, Y_train)\n",
    "        qualities.append(quality)\n",
    "\n",
    "    return qualities    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## MAIN Exercise = Select 5 best features\n",
    "alpha = 0.03\n",
    "max_iterations = 1000\n",
    "qualities = pd.Series(quality_by_iteration(alpha, max_iterations))  \n",
    "\n",
    "def test_accuracy(X_train, Y_train, X_test, Y_test):\n",
    "    final_theta = predictions_by_iteration = gradient_descent(X_train, Y_train, alpha, max_iterations)[1]\n",
    "    predictions = sig(np.dot(X_test,final_theta))\n",
    "    crisp = pd.Series(predictions).apply(crisp_predictor)\n",
    "    return accuracy(crisp, Y_test.values)\n",
    "    \n",
    "\n",
    "def find_best_features(X_train, Y_train, X_test, Y_test, max_features=5):\n",
    "    all_features = np.asarray(X_train.columns.values)\n",
    "    iterating_over = [0]\n",
    "    features_added = 0\n",
    "    for_comparison = { 'Nr of Features': [], 'Feature added': [], 'Accuracies': []}\n",
    "    \n",
    "    while (features_added < max_features):\n",
    "        print(\"Adding feature nr \", features_added + 1)\n",
    "        accuracy_with_added_feature = {}    \n",
    "        for feature in all_features:\n",
    "            with_added_feature = list(iterating_over)\n",
    "            \n",
    "            # Add feature to dataset for iteration\n",
    "            if feature in with_added_feature:\n",
    "                # print(\"feature already in dataset\", feature)\n",
    "                continue\n",
    "            with_added_feature.append(feature) \n",
    "            new_X_train = X_train[with_added_feature]\n",
    "            new_X_test = X_test[with_added_feature]\n",
    "\n",
    "            calculated_accuracy = test_accuracy(new_X_train, Y_train, new_X_test, Y_test)\n",
    "            accuracy_with_added_feature[feature] = calculated_accuracy\n",
    "        \n",
    "        features_added += 1\n",
    "   \n",
    "        best_feature_to_add = max(accuracy_with_added_feature.items(), key=operator.itemgetter(1))[0]\n",
    "        #print(f\"Addiing feature # {best_feature_to_add} with added accuracy of {accuracy_with_added_feature[best_feature_to_add]}.\")\n",
    "        iterating_over.append(best_feature_to_add)\n",
    "        \n",
    "        for_comparison['Nr of Features'].append(features_added)\n",
    "        for_comparison['Feature added'].append(best_feature_to_add)\n",
    "        for_comparison['Accuracies'].append(accuracy_with_added_feature[best_feature_to_add])\n",
    "\n",
    "    print(f\"Finished finding {features_added} best features...\")    \n",
    "    return(for_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding feature nr  1\n",
      "Adding feature nr  2\n",
      "Adding feature nr  3\n",
      "Adding feature nr  4\n",
      "Adding feature nr  5\n",
      "Finished finding 5 best features...\n"
     ]
    }
   ],
   "source": [
    "accuracies_by_nr_of_features = find_best_features(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracies': [92.193308550185876,\n",
       "  95.167286245353154,\n",
       "  96.282527881040892,\n",
       "  96.6542750929368,\n",
       "  97.026022304832722,\n",
       "  97.77],\n",
       " 'Feature added': [8, 24, 28, 11, 12, <function all>],\n",
       " 'Nr of Features': [1, 2, 3, 4, 5, 31]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies_by_nr_of_features['Nr of Features'].append(31)\n",
    "accuracies_by_nr_of_features['Accuracies'].append(97.77)\n",
    "accuracies_by_nr_of_features['Feature added'].append(all)\n",
    "accuracies_by_nr_of_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(accuracies_by_nr_of_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d752f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nr of Features'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAFdCAYAAADSax5EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlLSZQJ34EUYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d641438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = df.plot(x='Nr of Features', y='Accuracies', kind='bar', label=\"Accuracy in %\")\n",
    "ax.set_ylim(90,100)\n",
    "ax.get_xlabel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
